{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-03T20:25:19.535904Z",
     "start_time": "2024-10-03T20:24:54.795838Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Função para carregar o modelo GloVe pré-treinado\n",
    "def load_glove_model(glove_file):\n",
    "    print(\"Carregando modelo GloVe...\")\n",
    "    glove_model = {}\n",
    "    with open(glove_file, 'r', encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            # Tentar carregar a linha, ignorar se houver erro de conversão\n",
    "            try:\n",
    "                # Substituir vírgulas por pontos e remover possíveis caracteres indesejados\n",
    "                split_line = line.replace(',', '.').split()\n",
    "                \n",
    "                # A primeira parte da linha deve ser a palavra\n",
    "                word = split_line[0]\n",
    "                \n",
    "                # O restante da linha deve ser o vetor numérico\n",
    "                vector = np.array(split_line[1:], dtype=float)\n",
    "                \n",
    "                # Adicionar ao dicionário\n",
    "                glove_model[word] = vector\n",
    "            \n",
    "            except ValueError:\n",
    "                # Ignorar linhas que não possam ser convertidas para float\n",
    "                print(f\"Erro ao carregar linha: {line.strip()} - Linha ignorada.\")\n",
    "                continue\n",
    "    \n",
    "    print(f\"Modelo GloVe carregado com {len(glove_model)} palavras.\")\n",
    "    return glove_model\n",
    "\n",
    "# Especifique o caminho para o arquivo GloVe\n",
    "glove_file = '../Models/glove_s50.txt'  # Altere para o caminho correto\n",
    "\n",
    "# Carregar o modelo GloVe\n",
    "glove_model = load_glove_model(glove_file)\n",
    "\n",
    "# Verificar o vetor de uma palavra (por exemplo, \"computer\")\n",
    "word = \"computer\"\n",
    "if word in glove_model:\n",
    "    print(f\"Vetor para a palavra '{word}':\\n\", glove_model[word])\n",
    "else:\n",
    "    print(f\"A palavra '{word}' não está no vocabulário.\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carregando modelo GloVe...\n",
      "Erro ao carregar linha: 00 % 0.238321 0.428413 -0.052815 0.285182 -0.132642 0.074867 -0.156668 -0.136985 -0.121049 -0.014800 -0.075628 0.235240 -0.303932 -0.146515 -0.018260 -0.028394 -0.083194 0.216203 -0.331248 -0.320542 0.290555 0.066519 0.027326 0.177007 -0.077733 0.084656 -0.085467 -0.072151 0.092679 -0.172570 0.111656 0.072783 0.106959 0.265846 -0.015970 0.132251 -0.033092 0.087407 0.063407 0.112884 -0.029037 0.012749 0.086987 0.042678 0.080592 -0.028452 0.153930 -0.126905 -0.129614 0.174028 - Linha ignorada.\n",
      "Erro ao carregar linha: 三藏法師玄奘奉　詔譯 0.126251 0.044369 0.216259 0.243329 -0.122597 -0.006277 -0.092619 0.039339 0.070852 -0.266326 -0.191690 0.025615 0.212125 -0.113988 0.213476 0.223095 -0.217400 0.038813 0.008619 -0.062391 -0.040933 -0.204107 0.026779 0.220275 0.225373 0.140602 -0.049127 0.076664 0.141255 -0.213412 0.094084 -0.171865 -0.038348 -0.050799 0.028407 0.193167 0.067945 0.151280 0.089024 -0.142448 -0.097696 -0.004128 0.130937 0.088114 0.035505 0.004695 0.049613 0.112446 0.050219 0.137906 - Linha ignorada.\n",
      "Modelo GloVe carregado com 928639 palavras.\n",
      "Vetor para a palavra 'computer':\n",
      " [ 0.134774 -0.304108 -0.440682 -0.492802 -0.66668   0.527508 -0.040762\n",
      " -0.417407 -0.193834  0.638514  0.514523 -2.020896  0.300572  1.165496\n",
      "  0.408248  0.599102 -0.351722  0.118131  0.458306 -0.474252 -1.246619\n",
      "  0.058717  0.345981  0.779994 -0.739161  0.250835  0.325872  0.694905\n",
      " -0.056338  0.644624  0.120426 -0.50445  -1.003133 -1.834501  0.421963\n",
      "  0.487644 -0.242339  0.344822  0.299803 -0.048971 -0.295091 -0.198698\n",
      " -0.219312 -0.475548 -0.380676  0.350264  0.621291 -1.375281  0.497693\n",
      " -1.039931]\n"
     ]
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-03T20:25:19.567433Z",
     "start_time": "2024-10-03T20:25:19.538658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "# Exemplo de dataset com títulos de artigos de pesquisa científica\n",
    "data = {\n",
    "    'document': [\n",
    "        \"Deep learning for image recognition and classification\",\n",
    "        \"Quantum computing applications in cryptography\",\n",
    "        \"Advances in renewable energy systems and technologies\",\n",
    "        \"Blockchain technology and its impact on financial systems\",\n",
    "        \"Natural language processing techniques for text classification\",\n",
    "        \"Artificial intelligence in healthcare and medical diagnosis\",\n",
    "        \"Data mining techniques for big data analytics\",\n",
    "        \"Cybersecurity challenges in cloud computing environments\",\n",
    "        \"Machine learning algorithms for predictive modeling\",\n",
    "        \"Internet of things and smart cities\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Tokenizar os documentos\n",
    "df['tokens'] = df['document'].apply(lambda x: word_tokenize(x.lower()))\n",
    "\n",
    "# Função para converter um documento ou consulta em um vetor GloVe médio\n",
    "def get_average_vector(tokens_list, glove_model):\n",
    "    vectors = [glove_model[word] for word in tokens_list if word in glove_model]\n",
    "    if len(vectors) > 0:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(100)  # Usar um vetor de zeros se nenhuma palavra estiver no modelo\n",
    "\n",
    "# Criar vetores médios para os documentos\n",
    "df['vector'] = df['tokens'].apply(lambda x: get_average_vector(x, glove_model))\n",
    "\n",
    "# Função para pesquisar documentos com base na similaridade semântica\n",
    "def pesquisar_documentos(consulta, df, glove_model, top_n=3):\n",
    "    # Pré-processar a consulta e convertê-la em vetor GloVe\n",
    "    consulta_tokens = word_tokenize(consulta.lower())\n",
    "    consulta_vector = get_average_vector(consulta_tokens, glove_model)\n",
    "    \n",
    "    # Calcular a similaridade de cosseno entre a consulta e os documentos\n",
    "    df['similarity'] = df['vector'].apply(lambda x: cosine_similarity([consulta_vector], [x])[0][0])\n",
    "    \n",
    "    # Ordenar os documentos pela similaridade e retornar os top_n mais relevantes\n",
    "    documentos_relevantes = df.sort_values(by='similarity', ascending=False).head(top_n)\n",
    "    \n",
    "    return documentos_relevantes[['document', 'similarity']]\n",
    "\n",
    "# Exemplo de uso: consulta do usuário\n"
   ],
   "id": "4d055fad18983250",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos mais relevantes para a consulta: 'Applications of machine learning in healthcare':\n",
      "\n",
      "                                            document  similarity\n",
      "1     Quantum computing applications in cryptography    0.945626\n",
      "5  Artificial intelligence in healthcare and medi...    0.937943\n",
      "0  Deep learning for image recognition and classi...    0.934165\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-04T00:57:51.846260Z",
     "start_time": "2024-10-04T00:57:51.627773Z"
    }
   },
   "cell_type": "code",
   "source": [
    "consulta = \"Applications of machine learning in healthcare\"\n",
    "documentos_relevantes = pesquisar_documentos(consulta, df, glove_model, top_n=3)\n",
    "\n",
    "# Exibir os resultados da pesquisa\n",
    "print(f\"Documentos mais relevantes para a consulta: '{consulta}':\\n\")\n",
    "print(documentos_relevantes)\n"
   ],
   "id": "93f43d3a610b6a95",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos mais relevantes para a consulta: 'Applications of machine learning in healthcare':\n",
      "\n",
      "                                            document  similarity\n",
      "1     Quantum computing applications in cryptography    0.945626\n",
      "5  Artificial intelligence in healthcare and medi...    0.937943\n",
      "0  Deep learning for image recognition and classi...    0.934165\n"
     ]
    }
   ],
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
