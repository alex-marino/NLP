{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# O objetivo desta tarefa é gerar, dado um conjunto de documentos, gerar vetore de características:\n",
    " - TF (frequência do termo)\n",
    " - TFIDF (Frequência do Termo e Frequência inversa do DOcumento)\n",
    "\n",
    "Ao término da tarefa você deve gerar os vetores para os datasets contidos na pasta DATA."
   ],
   "id": "e6740baf1de3f894"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preparação do Ambiente",
   "id": "987a8f0f74f64055"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:32:00.219754Z",
     "start_time": "2024-09-05T18:31:59.886788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n"
   ],
   "id": "eca97ffb09f3445a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/alexmarino/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/alexmarino/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/alexmarino/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:13:37.892954Z",
     "start_time": "2024-09-05T18:13:37.271635Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ],
   "id": "11f23e47f2b7350a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Importar dataset",
   "id": "91866e9ac56be0c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:23:06.445411Z",
     "start_time": "2024-09-05T18:23:06.407007Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv('../DATA/data.csv')\n",
    "df.head(2)"
   ],
   "id": "dc7e2ae11652eec8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                            Sentence Sentiment\n",
       "0  The GeoSolutions technology will leverage Bene...  positive\n",
       "1  $ESI on lows, down $1.50 to $2.50 BK a real po...  negative"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Pontuação para NLP",
   "id": "e7e654d684406ff0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:18:47.815515Z",
     "start_time": "2024-09-05T18:18:47.793750Z"
    }
   },
   "cell_type": "code",
   "source": "df['clean_punct'] = df['Sentence'].str.replace('[,.:;!?]+', ' ', regex=True).copy()",
   "id": "706ad5c1102a5427",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:23:19.276223Z",
     "start_time": "2024-09-05T18:23:19.243883Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['clean_punct'] = df['Sentence'].str.replace ('[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', regex=True).copy()\n",
    "df"
   ],
   "id": "1320e07188e82cd5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Sentence Sentiment  \\\n",
       "0     The GeoSolutions technology will leverage Bene...  positive   \n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative   \n",
       "2     For the last quarter of 2010 , Componenta 's n...  positive   \n",
       "3     According to the Finnish-Russian Chamber of Co...   neutral   \n",
       "4     The Swedish buyout firm has sold its remaining...   neutral   \n",
       "...                                                 ...       ...   \n",
       "5837  RISING costs have forced packaging producer Hu...  negative   \n",
       "5838  Nordic Walking was first used as a summer trai...   neutral   \n",
       "5839  According shipping company Viking Line , the E...   neutral   \n",
       "5840  In the building and home improvement trade , s...   neutral   \n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive   \n",
       "\n",
       "                                            clean_punct  \n",
       "0     The GeoSolutions technology will leverage Bene...  \n",
       "1      ESI on lows, down  1.50 to  2.50 BK a real po...  \n",
       "2     For the last quarter of 2010 , Componenta  s n...  \n",
       "3     According to the Finnish Russian Chamber of Co...  \n",
       "4     The Swedish buyout firm has sold its remaining...  \n",
       "...                                                 ...  \n",
       "5837  RISING costs have forced packaging producer Hu...  \n",
       "5838  Nordic Walking was first used as a summer trai...  \n",
       "5839  According shipping company Viking Line , the E...  \n",
       "5840  In the building and home improvement trade , s...  \n",
       "5841  HELSINKI AFX   KCI Konecranes said it has won ...  \n",
       "\n",
       "[5842 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ESI on lows, down  1.50 to  2.50 BK a real po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>For the last quarter of 2010 , Componenta  s n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>According to the Finnish Russian Chamber of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>HELSINKI AFX   KCI Konecranes said it has won ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Números para NLP",
   "id": "416c48f411f587f4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:25:14.453349Z",
     "start_time": "2024-09-05T18:25:14.388136Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df['clean_punct'] = df['clean_punct'].str.replace('[0-9]+', '', regex=True).copy()\n",
    "df['clean_punct'] = df['clean_punct'].str.replace ('[/<>()|\\+\\-\\$%&#@\\'\\\"]+', ' ', regex=True).copy()\n",
    "df['clean_punct'] = df['clean_punct'].str.replace ('[,.:;!?]+', ' ', regex=True).copy()\n",
    "df"
   ],
   "id": "8d3b1c1edaf35de9",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                                               Sentence Sentiment  \\\n",
       "0     The GeoSolutions technology will leverage Bene...  positive   \n",
       "1     $ESI on lows, down $1.50 to $2.50 BK a real po...  negative   \n",
       "2     For the last quarter of 2010 , Componenta 's n...  positive   \n",
       "3     According to the Finnish-Russian Chamber of Co...   neutral   \n",
       "4     The Swedish buyout firm has sold its remaining...   neutral   \n",
       "...                                                 ...       ...   \n",
       "5837  RISING costs have forced packaging producer Hu...  negative   \n",
       "5838  Nordic Walking was first used as a summer trai...   neutral   \n",
       "5839  According shipping company Viking Line , the E...   neutral   \n",
       "5840  In the building and home improvement trade , s...   neutral   \n",
       "5841  HELSINKI AFX - KCI Konecranes said it has won ...  positive   \n",
       "\n",
       "                                            clean_punct  \n",
       "0     The GeoSolutions technology will leverage Bene...  \n",
       "1      ESI on lows  down    to    BK a real possibility  \n",
       "2     For the last quarter of    Componenta  s net s...  \n",
       "3     According to the Finnish Russian Chamber of Co...  \n",
       "4     The Swedish buyout firm has sold its remaining...  \n",
       "...                                                 ...  \n",
       "5837  RISING costs have forced packaging producer Hu...  \n",
       "5838  Nordic Walking was first used as a summer trai...  \n",
       "5839  According shipping company Viking Line   the E...  \n",
       "5840  In the building and home improvement trade   s...  \n",
       "5841  HELSINKI AFX   KCI Konecranes said it has won ...  \n",
       "\n",
       "[5842 rows x 3 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>clean_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "      <td>positive</td>\n",
       "      <td>The GeoSolutions technology will leverage Bene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>$ESI on lows, down $1.50 to $2.50 BK a real po...</td>\n",
       "      <td>negative</td>\n",
       "      <td>ESI on lows  down    to    BK a real possibility</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>For the last quarter of 2010 , Componenta 's n...</td>\n",
       "      <td>positive</td>\n",
       "      <td>For the last quarter of    Componenta  s net s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>According to the Finnish-Russian Chamber of Co...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>According to the Finnish Russian Chamber of Co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>The Swedish buyout firm has sold its remaining...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5837</th>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "      <td>negative</td>\n",
       "      <td>RISING costs have forced packaging producer Hu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5838</th>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Nordic Walking was first used as a summer trai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5839</th>\n",
       "      <td>According shipping company Viking Line , the E...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>According shipping company Viking Line   the E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5840</th>\n",
       "      <td>In the building and home improvement trade , s...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>In the building and home improvement trade   s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5841</th>\n",
       "      <td>HELSINKI AFX - KCI Konecranes said it has won ...</td>\n",
       "      <td>positive</td>\n",
       "      <td>HELSINKI AFX   KCI Konecranes said it has won ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5842 rows × 3 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Remoçao de Stop Words",
   "id": "1b62071cc88a0299"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:26:48.788779Z",
     "start_time": "2024-09-05T18:26:48.777815Z"
    }
   },
   "cell_type": "code",
   "source": [
    "stop_words = stopwords.words('english')\n",
    "stop_words"
   ],
   "id": "2229534195928ade",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Tokenização",
   "id": "81e2d6052de4ba09"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:32:05.912372Z",
     "start_time": "2024-09-05T18:32:05.883264Z"
    }
   },
   "cell_type": "code",
   "source": [
    "sentence = df[\"clean_punct\"].iloc[1]\n",
    "nltk.word_tokenize(sentence)\n"
   ],
   "id": "6d77a485be606089",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ESI', 'on', 'lows', 'down', 'to', 'BK', 'a', 'real', 'possibility']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## CountVectorizer",
   "id": "af47952f755a854d"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:34:42.302138Z",
     "start_time": "2024-09-05T18:34:42.282933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "countVectorizer = CountVectorizer(strip_accents='ascii', \n",
    "                      lowercase=True, \n",
    "                      stop_words=stop_words)\n",
    "countVectorizer.fit(df['clean_punct'][:2])"
   ],
   "id": "997f6522a4a0b77c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words=['i', 'me', 'my', 'myself', 'we', 'our', 'ours',\n",
       "                            'ourselves', 'you', \"you're\", \"you've\", \"you'll\",\n",
       "                            \"you'd\", 'your', 'yours', 'yourself', 'yourselves',\n",
       "                            'he', 'him', 'his', 'himself', 'she', \"she's\",\n",
       "                            'her', 'hers', 'herself', 'it', \"it's\", 'its',\n",
       "                            'itself', ...],\n",
       "                strip_accents='ascii')"
      ],
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                strip_accents=&#x27;ascii&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(stop_words=[&#x27;i&#x27;, &#x27;me&#x27;, &#x27;my&#x27;, &#x27;myself&#x27;, &#x27;we&#x27;, &#x27;our&#x27;, &#x27;ours&#x27;,\n",
       "                            &#x27;ourselves&#x27;, &#x27;you&#x27;, &quot;you&#x27;re&quot;, &quot;you&#x27;ve&quot;, &quot;you&#x27;ll&quot;,\n",
       "                            &quot;you&#x27;d&quot;, &#x27;your&#x27;, &#x27;yours&#x27;, &#x27;yourself&#x27;, &#x27;yourselves&#x27;,\n",
       "                            &#x27;he&#x27;, &#x27;him&#x27;, &#x27;his&#x27;, &#x27;himself&#x27;, &#x27;she&#x27;, &quot;she&#x27;s&quot;,\n",
       "                            &#x27;her&#x27;, &#x27;hers&#x27;, &#x27;herself&#x27;, &#x27;it&#x27;, &quot;it&#x27;s&quot;, &#x27;its&#x27;,\n",
       "                            &#x27;itself&#x27;, ...],\n",
       "                strip_accents=&#x27;ascii&#x27;)</pre></div></div></div></div></div>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:35:21.347068Z",
     "start_time": "2024-09-05T18:35:21.340080Z"
    }
   },
   "cell_type": "code",
   "source": "countVectorizer.get_feature_names_out()",
   "id": "47301fb4103a8c35",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['based', 'benefon', 'bk', 'commercial', 'communities', 'content',\n",
       "       'esi', 'geosolutions', 'gps', 'leverage', 'location', 'lows',\n",
       "       'model', 'multimedia', 'new', 'platform', 'possibility',\n",
       "       'powerful', 'providing', 'real', 'relevant', 'search', 'solutions',\n",
       "       'technology'], dtype=object)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T18:37:19.369600Z",
     "start_time": "2024-09-05T18:37:19.361736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MTX = countVectorizer.transform(df['clean_punct'][:2])\n",
    "MTX.toarray()"
   ],
   "id": "82c776ee31350e93",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 2, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1,\n",
       "        1, 2],\n",
       "       [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        0, 0]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## TFIDF",
   "id": "9a189ec82d33cb8f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T19:39:08.194094Z",
     "start_time": "2024-09-05T19:39:08.189929Z"
    }
   },
   "cell_type": "code",
   "source": "tfidf = TfidfTransformer(use_idf=True, norm=\"l2\")",
   "id": "ec735725f034ee0a",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# usando a matriz de frequência para gerar tfidf ",
   "id": "49c20d75aa509d54"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-05T19:43:34.689535Z",
     "start_time": "2024-09-05T19:43:34.673175Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tfVectorizer = tfidf.fit(MTX)\n",
    "DTM = tfVectorizer.transform(MTX)\n",
    "DTM.toarray()"
   ],
   "id": "3fd48ed3dedee5aa",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2      , 0.2      , 0.       , 0.2      , 0.2      , 0.2      ,\n",
       "        0.       , 0.2      , 0.2      , 0.2      , 0.4      , 0.       ,\n",
       "        0.2      , 0.2      , 0.2      , 0.2      , 0.       , 0.2      ,\n",
       "        0.2      , 0.       , 0.2      , 0.2      , 0.2      , 0.4      ],\n",
       "       [0.       , 0.       , 0.4472136, 0.       , 0.       , 0.       ,\n",
       "        0.4472136, 0.       , 0.       , 0.       , 0.       , 0.4472136,\n",
       "        0.       , 0.       , 0.       , 0.       , 0.4472136, 0.       ,\n",
       "        0.       , 0.4472136, 0.       , 0.       , 0.       , 0.       ]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "5f76a69c19ed42d4"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Para todos que chegarm neste ponto deve efetuar as seguintes tafefas:\n",
    "\n",
    "\n",
    "1 - Elaborar um gáfico de termos mais frequentes consierando os seguintes ranges de ngram:\n",
    "    ngram(1,1)\n",
    "    ngram(1,2)\n",
    "    ngram(2,2)\n",
    "    ngram(2,3)\n",
    "    \n",
    "2 - Elaborar wordcloud para as configurações de NGRAM acima.\n",
    "\n",
    "3 - Investigar o efeito da remoção da lista de stoprods no tamanho do dicionário final.\n",
    "\n",
    "4 - Investigar as técnicas de normalização l1 e l2."
   ],
   "id": "4f4f1339d882e9c0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
